#!/usr/bin/env python3

import os
try:
    del os.environ['RAY_RUNTIME_ENV_HOOK']
except KeyError:
    pass

try:
    del os.environ['RAY_JOB_SUBMIT_HOOK']
except KeyError:
    pass

with_actors = os.environ['USE_ACTORS_OR_TASKS'].lower() == 'actors'
with_gpu = os.environ['WITH_GPU'].lower() == 'true'

import ray
import time

print('driver script pid', os.getpid())

@ray.remote
def task(scheduling_start_time):
    dur_s = time.time() - scheduling_start_time
    print(f'scheduling time {dur_s:.02f}')
    ctx = ray.runtime_context.get_runtime_context()
    assert ctx.runtime_env == {}, f"expected runtime env to be empty, got {ctx.runtime_env}"

    print('task pid', os.getpid())
    print(f'task job id {ctx.get_job_id()}')

    start = time.time()
    import torch
    import tensorflow
    dur_s = time.time() - start
    print(f'imports took {dur_s:.02f}')

    metrics_actor.report_completion.remote()
    while not ray.get(metrics_actor.run_has_ended.remote()):
        time.sleep(1)

@ray.remote
class Actor:
    def __init__(self, scheduling_start_time):
        dur_s = time.time() - scheduling_start_time
        print(f'scheduling time {dur_s:.02f}')

    def do_imports(self):
        start = time.time()
        import torch
        import tensorflow
        dur_s = time.time() - start
        print(f'imports took {dur_s:.02f}')

        ctx = ray.runtime_context.get_runtime_context()
        assert ctx.runtime_env == {}, f"expected runtime env to be empty, got {ctx.runtime_env}"
        print(f'actor job id {ctx.get_job_id()}')

        metrics_actor.report_completion.remote()
        while not ray.get(metrics_actor.run_has_ended.remote()):
            time.sleep(1)

@ray.remote(num_cpus=1)
class MetricsActor:
    def __init__(self):
        ctx = ray.runtime_context.get_runtime_context()
        print(f"metrics actor job_id {ctx.get_job_id()}")

        self.run_size = 0
        self.completed = 0
        self.run_start_time = 0
        self.run_dur_s = None

    def ready(self):
        return True

    def begin_run(self, num):
        self.run_size = num
        self.completed = 0
        self.run_start_time = time.time()
        self.run_dur_s = None

    def report_completion(self):
        self.completed += 1
        if self.run_dur_s is None and self.run_has_ended():
            self.run_dur_s = time.time() - self.run_start_time
            print(f'report_completion scheduling plus imports of {self.run_size}: {self.run_dur_s:.02f}')

    def run_has_ended(self):
        assert self.run_size > 0
        return self.completed == self.run_size

    def get_last_dur_s(self):
        return self.run_dur_s

def create_metrics_actor():
    metrics_actor = MetricsActor.options(name="metrics", namespace="metrics_ns").remote()
    ray.get(metrics_actor.ready.remote())
    return metrics_actor

try:
    metrics_actor = ray.get_actor(name="metrics", namespace="metrics_ns")
except ValueError:
    metrics_actor = create_metrics_actor()

num_cpus = os.cpu_count()
num_gpu_present = 1
num_executables = num_cpus - 2
num_gpus = (num_gpu_present / num_executables) if with_gpu else 0

ray.get(metrics_actor.begin_run.remote(num_executables))
scheduling_start_time = time.time()

if with_actors:
    actors = [
        Actor.options(
            num_gpus=num_gpus,
        ).remote(scheduling_start_time)
        for _ in range(num_executables)
    ]
    ray.get([a.do_imports.remote() for a in actors])
else:
    ray.get([
        task.options(
            num_gpus=num_gpus,
        ).remote(scheduling_start_time)
        for _ in range(num_executables)
    ])
dur_s = time.time() - scheduling_start_time

time.sleep(1)

print(f'num_cpus: {num_cpus}')
print(f'num_executables: {num_executables}')
